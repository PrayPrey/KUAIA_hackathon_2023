{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset, TensorDataset, Subset\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import chart_studio.plotly as py\n",
    "import plotly.graph_objects as go\n",
    "import cufflinks as cf\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "cf.go_offline(connected = True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total = pd.read_excel('Final.xlsx',index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list_normal = pd.read_excel('MuSinSa_photo/Total_page_info.xlsx',index_col= 0)\n",
    "\n",
    "lst_total = df_list_normal['index'].values\n",
    "\n",
    "len(lst_total), lst_total\n",
    "\n",
    "df_musina = pd.read_excel('First_to_Second_page.xlsx',index_col = 0).reset_index()\n",
    "\n",
    "df_musina['index'] = [i for i in range(df_musina.shape[0])]\n",
    "\n",
    "df_musina_2 = df_musina.iloc[df_list_normal['index'].values,:].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['아메리칸 캐주얼', '캐주얼', '댄디', '포멀', '걸리시', '골프', '홈웨어', '레트로', '로맨틱',\n",
       "       '스포츠', '스트릿', '시크'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total['style'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_index</th>\n",
       "      <th>class_id</th>\n",
       "      <th>prob</th>\n",
       "      <th>style</th>\n",
       "      <th>style_part</th>\n",
       "      <th>comment</th>\n",
       "      <th>tag</th>\n",
       "      <th>coordinate</th>\n",
       "      <th>domain_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[8, 4, 2]</td>\n",
       "      <td>[0.8417168259620667, 0.8145477771759033, 0.741...</td>\n",
       "      <td>아메리칸 캐주얼</td>\n",
       "      <td>아메카지 멋 내기</td>\n",
       "      <td>브라운 컬러가 돋보이는 카디건과 코튼 팬츠를 코디하고 숏 패딩과 머플러를 더해 완성...</td>\n",
       "      <td>['겨울', '아메리칸 캐주얼', '구두', '로스트가든', '메신저/크로스 백',...</td>\n",
       "      <td>[[372, 136, 600, 307], [58, 23, 536, 427], [54...</td>\n",
       "      <td>https://store.musinsa.com/app/codimap/views/20899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[4, 8]</td>\n",
       "      <td>[0.9969467520713806, 0.7027121186256409]</td>\n",
       "      <td>아메리칸 캐주얼</td>\n",
       "      <td>아메카지 멋 내기</td>\n",
       "      <td>브라운 컬러가 돋보이는 카디건과 코튼 팬츠를 코디하고 숏 패딩과 머플러를 더해 완성...</td>\n",
       "      <td>['겨울', '아메리칸 캐주얼', '구두', '로스트가든', '메신저/크로스 백',...</td>\n",
       "      <td>[[81, 74, 601, 422], [437, 122, 601, 362]]</td>\n",
       "      <td>https://store.musinsa.com/app/codimap/views/20899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniq_index   class_id                                               prob  \\\n",
       "0           0  [8, 4, 2]  [0.8417168259620667, 0.8145477771759033, 0.741...   \n",
       "1           1     [4, 8]           [0.9969467520713806, 0.7027121186256409]   \n",
       "\n",
       "      style style_part                                            comment  \\\n",
       "0  아메리칸 캐주얼  아메카지 멋 내기  브라운 컬러가 돋보이는 카디건과 코튼 팬츠를 코디하고 숏 패딩과 머플러를 더해 완성...   \n",
       "1  아메리칸 캐주얼  아메카지 멋 내기  브라운 컬러가 돋보이는 카디건과 코튼 팬츠를 코디하고 숏 패딩과 머플러를 더해 완성...   \n",
       "\n",
       "                                                 tag  \\\n",
       "0  ['겨울', '아메리칸 캐주얼', '구두', '로스트가든', '메신저/크로스 백',...   \n",
       "1  ['겨울', '아메리칸 캐주얼', '구두', '로스트가든', '메신저/크로스 백',...   \n",
       "\n",
       "                                          coordinate  \\\n",
       "0  [[372, 136, 600, 307], [58, 23, 536, 427], [54...   \n",
       "1         [[81, 74, 601, 422], [437, 122, 601, 362]]   \n",
       "\n",
       "                                          domain_url  \n",
       "0  https://store.musinsa.com/app/codimap/views/20899  \n",
       "1  https://store.musinsa.com/app/codimap/views/20899  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8  9  2 10  0  1 11  3  4  6  5  7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items=['아메리칸 캐주얼', '캐주얼', '댄디', '포멀', '걸리시', '골프', '홈웨어', '레트로', '로맨틱',\n",
    "       '스포츠', '스트릿', '시크']\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(items)\n",
    "labels = encoder.transform(items)\n",
    "print(labels)\n",
    "len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_2 = df_total.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.transform(['아메리칸 캐주얼'])[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulate(row):\n",
    "    row['style'] = encoder.transform([row['style']])[0]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_total_3 = df_total_2.apply(manipulate,axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>uniq_index</th>\n",
       "      <th>class_id</th>\n",
       "      <th>prob</th>\n",
       "      <th>style</th>\n",
       "      <th>style_part</th>\n",
       "      <th>comment</th>\n",
       "      <th>tag</th>\n",
       "      <th>coordinate</th>\n",
       "      <th>domain_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[8, 4, 2]</td>\n",
       "      <td>[0.8417168259620667, 0.8145477771759033, 0.741...</td>\n",
       "      <td>8</td>\n",
       "      <td>아메카지 멋 내기</td>\n",
       "      <td>브라운 컬러가 돋보이는 카디건과 코튼 팬츠를 코디하고 숏 패딩과 머플러를 더해 완성...</td>\n",
       "      <td>['겨울', '아메리칸 캐주얼', '구두', '로스트가든', '메신저/크로스 백',...</td>\n",
       "      <td>[[372, 136, 600, 307], [58, 23, 536, 427], [54...</td>\n",
       "      <td>https://store.musinsa.com/app/codimap/views/20899</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   uniq_index   class_id                                               prob  \\\n",
       "0           0  [8, 4, 2]  [0.8417168259620667, 0.8145477771759033, 0.741...   \n",
       "\n",
       "   style style_part                                            comment  \\\n",
       "0      8  아메카지 멋 내기  브라운 컬러가 돋보이는 카디건과 코튼 팬츠를 코디하고 숏 패딩과 머플러를 더해 완성...   \n",
       "\n",
       "                                                 tag  \\\n",
       "0  ['겨울', '아메리칸 캐주얼', '구두', '로스트가든', '메신저/크로스 백',...   \n",
       "\n",
       "                                          coordinate  \\\n",
       "0  [[372, 136, 600, 307], [58, 23, 536, 427], [54...   \n",
       "\n",
       "                                          domain_url  \n",
       "0  https://store.musinsa.com/app/codimap/views/20899  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_total_3.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fe = pd.Series(df_total_3['class_id'].values)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 4, 2]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[int(W) for W in fe.replace('[','').replace(']','').split(',')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████| 6973/6973 [00:02<00:00, 3351.67it/s]\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "\n",
    "A = pd.DataFrame(np.zeros((6973, 14)))\n",
    "for idx,(i,j,y) in enumerate(tqdm.tqdm(df_total_3[['class_id','prob','style']].values)):\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    if i == 0:\n",
    "        A.loc[idx,14] = y\n",
    "    \n",
    "    else:\n",
    "        i  = [float(W) for W in i.replace('[','').replace(']','').split(',')]\n",
    "        j  = [float(W) for W in j.replace('[','').replace(']','').split(',')]    \n",
    "        if len(i) == 1:\n",
    "            A.loc[idx,i[0]] = j[0]\n",
    "            A.loc[idx,14] = y\n",
    "        else:\n",
    "            for idx_1 in range(len(i)):\n",
    "                A.loc[idx,i[idx_1]] = j[idx_1]\n",
    "            A.loc[idx,14] = y\n",
    "    \n",
    "\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TensorDataset(torch.from_numpy(A.iloc[:,:13].values + 0.01),torch.from_numpy(A.iloc[:,14].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "VAR = 0.2\n",
    "train_indices, val_indices = train_test_split(range(A.iloc[:,:13].shape[0]),\n",
    "                                             test_size = VAR)\n",
    "\n",
    "train_dataset = Subset(dataset, train_indices)\n",
    "validation_dataset = Subset(dataset, val_indices)\n",
    "\n",
    "minibatch_size = 128\n",
    "\n",
    "\n",
    "train_batches = DataLoader(train_dataset, batch_size = minibatch_size, shuffle = True)\n",
    "val_batches = DataLoader(validation_dataset, batch_size = minibatch_size, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self,input_dim,output_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.linear_layers = nn.Sequential(nn.Linear(input_dim, 200),\n",
    "                                          nn.LeakyReLU(0.1),\n",
    "                                          nn.Linear(200,100),\n",
    "                                          nn.LeakyReLU(0.1),\n",
    "                                          nn.Linear(100,50),\n",
    "                                          nn.LeakyReLU(0.1),\n",
    "                                          nn.Linear(50,20),\n",
    "                                          nn.LeakyReLU(0.1),\n",
    "                                          nn.Linear(20,5),\n",
    "                                          nn.LeakyReLU(0.1),\n",
    "                                          nn.Linear(5, output_dim), \n",
    "                                           # 최종 결과는 (20, 3) 이 되므로, dim=-1 로 label 확률값이 들어 있는 마지막 차원을 지정해줘야 함\n",
    "                                          nn.LogSoftmax(dim = -1)\n",
    "                                          )\n",
    "        \n",
    "    def forward(self,x):\n",
    "        y = self.linear_layers(x)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(1)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(1)\n",
    "print (device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13 12\n"
     ]
    }
   ],
   "source": [
    "input_dim = torch.from_numpy(A.iloc[:,:13].values).size(-1)\n",
    "output_dim = 12\n",
    "# 여기서는 12개의 label 이 있음!!\n",
    "\n",
    "print(input_dim, output_dim )\n",
    "\n",
    "model = Net(input_dim, output_dim).to(device)\n",
    "\n",
    "loss_func = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(2.5213, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "40 tensor(2.3594, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "80 tensor(2.3383, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "120 tensor(2.3237, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "160 tensor(2.3165, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "200 tensor(2.3055, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "240 tensor(2.3005, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "280 tensor(2.2937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "320 tensor(2.2898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "360 tensor(2.2866, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "400 tensor(2.2782, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "440 tensor(2.2699, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "480 tensor(2.2700, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "520 tensor(2.2650, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "560 tensor(2.2574, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "600 tensor(2.2533, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "640 tensor(2.2503, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "680 tensor(2.2454, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "720 tensor(2.2406, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "760 tensor(2.2360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "800 tensor(2.2335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "840 tensor(2.2258, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "880 tensor(2.2191, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "920 tensor(2.2153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "960 tensor(2.2143, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1000 tensor(2.2131, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1040 tensor(2.2084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1080 tensor(2.2049, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1120 tensor(2.1971, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1160 tensor(2.1955, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1200 tensor(2.1965, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1240 tensor(2.1884, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1280 tensor(2.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1320 tensor(2.1857, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1360 tensor(2.1758, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1400 tensor(2.1753, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1440 tensor(2.1713, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1480 tensor(2.1776, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1520 tensor(2.1751, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1560 tensor(2.1616, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1600 tensor(2.1665, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1640 tensor(2.1614, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1680 tensor(2.1618, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1720 tensor(2.1545, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1760 tensor(2.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1800 tensor(2.1498, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1840 tensor(2.1502, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1880 tensor(2.1372, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1920 tensor(2.1472, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "1960 tensor(2.1423, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2000 tensor(2.1345, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2040 tensor(2.1432, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2080 tensor(2.1360, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2120 tensor(2.1353, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2160 tensor(2.1419, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2200 tensor(2.1335, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2240 tensor(2.1338, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2280 tensor(2.1306, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2320 tensor(2.1236, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2360 tensor(2.1249, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2400 tensor(2.1204, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2440 tensor(2.1250, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2480 tensor(2.1208, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2520 tensor(2.1182, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2560 tensor(2.1190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2600 tensor(2.1088, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2640 tensor(2.1153, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2680 tensor(2.1136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2720 tensor(2.1255, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2760 tensor(2.1043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2800 tensor(2.1050, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2840 tensor(2.0999, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2880 tensor(2.0898, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2920 tensor(2.0952, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "2960 tensor(2.1042, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3000 tensor(2.1117, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3040 tensor(2.0969, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3080 tensor(2.1012, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3120 tensor(2.0910, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3160 tensor(2.0992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3200 tensor(2.0919, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3240 tensor(2.0873, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3280 tensor(2.0958, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3320 tensor(2.0883, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3360 tensor(2.1029, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3400 tensor(2.0769, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3440 tensor(2.0937, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3480 tensor(2.0832, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3520 tensor(2.0773, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3560 tensor(2.1025, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "3600 tensor(2.0739, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-8b5ccc1fd28d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     25\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;36m40\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m                 \u001b[0mprofile_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Optimizer.step#{}.step\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecord_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprofile_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 140\u001b[1;33m                     \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m                     \u001b[0mobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_optimizer_step_code\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m_use_grad\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m     21\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdefaults\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'differentiable'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m             \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprev_grad\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure, grad_scaler)\u001b[0m\n\u001b[0;32m    250\u001b[0m                  \u001b[0mfused\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'fused'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m                  \u001b[0mgrad_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_scale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m                  found_inf=found_inf)\n\u001b[0m\u001b[0;32m    253\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36madam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[0;32m    314\u001b[0m          \u001b[0mdifferentiable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdifferentiable\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m          \u001b[0mgrad_scale\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_scale\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m          found_inf=found_inf)\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36m_single_tensor_adam\u001b[1;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m         \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m         \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "nb_epochs = 10000\n",
    "\n",
    "X_train_tensor = torch.from_numpy(A.iloc[:,:13].values +0.1).type(torch.float32)\n",
    "y_train_tensor = torch.from_numpy(A.iloc[:,14].values).type(torch.LongTensor)\n",
    "\n",
    "model.train()\n",
    "for index in range(nb_epochs):\n",
    "    indices = torch.randperm(X_train_tensor.size(0))\n",
    "\n",
    "    x_batch_list = torch.index_select(X_train_tensor, 0, index=indices)\n",
    "    y_batch_list = torch.index_select(y_train_tensor, 0, index=indices)\n",
    "    x_batch_list = x_batch_list.split(minibatch_size, 0)\n",
    "    y_batch_list = y_batch_list.split(minibatch_size, 0)\n",
    "\n",
    "    epoch_loss = list()        \n",
    "    for x_minibatch, y_minibatch in zip(x_batch_list, y_batch_list):\n",
    "        \n",
    "        x_minibatch = x_minibatch.to(device)\n",
    "        y_minibatch = y_minibatch.to(device)\n",
    "        \n",
    "        y_minibatch_pred = model(x_minibatch)\n",
    "        loss = loss_func(y_minibatch_pred, y_minibatch)\n",
    "        epoch_loss.append(loss)        \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    if (index % 40) == 0:\n",
    "        print (index, sum(epoch_loss) / len(epoch_loss))        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.1000, 0.1000, 0.8415,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.8801,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        ...,\n",
       "        [0.1000, 0.1000, 0.9631,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000],\n",
       "        [0.1000, 0.1000, 0.1000,  ..., 0.1000, 0.1000, 0.1000]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'class_ids': array([8, 1]),\n",
    "#   'scores': array([0.99361986, 0.8832041 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (linear_layers): Sequential(\n",
       "    (0): Linear(in_features=13, out_features=200, bias=True)\n",
       "    (1): LeakyReLU(negative_slope=0.1)\n",
       "    (2): Linear(in_features=200, out_features=100, bias=True)\n",
       "    (3): LeakyReLU(negative_slope=0.1)\n",
       "    (4): Linear(in_features=100, out_features=50, bias=True)\n",
       "    (5): LeakyReLU(negative_slope=0.1)\n",
       "    (6): Linear(in_features=50, out_features=20, bias=True)\n",
       "    (7): LeakyReLU(negative_slope=0.1)\n",
       "    (8): Linear(in_features=20, out_features=5, bias=True)\n",
       "    (9): LeakyReLU(negative_slope=0.1)\n",
       "    (10): Linear(in_features=5, out_features=12, bias=True)\n",
       "    (11): LogSoftmax(dim=-1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(model(torch.Tensor([0,0.8832041 , 0, 0, 0, 0, 0, 0, 0.99361986, 0, 0, 0, 0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
